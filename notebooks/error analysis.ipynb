{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08121def-b144-4ff4-a101-4801033801bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/users/k21193529/conda/jenv3/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from main import load_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33bbc1c-2cd1-4e31-9c47-10c9d7871c35",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d9e765-9412-46e0-98d8-41bc7bcf5db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '../data_2023_06_02'\n",
    "\n",
    "fever_dir = os.path.join(root, 'preprocessed/FEVER')\n",
    "pubhealth_dir = os.path.join(root, 'preprocessed/PUBHEALTH')\n",
    "climate_dir = os.path.join(root, 'preprocessed/CLIMATE-FEVER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5564286-8466-48ae-a067-00bb00f39610",
   "metadata": {},
   "outputs": [],
   "source": [
    "climate_params = {\n",
    "    # 'dev_size': 150,\n",
    "    # 'test_size': 150,\n",
    "    # 'random_state': 88\n",
    "}\n",
    "\n",
    "ds_fever, ds_pubhealth, ds_climate, ds_test = load_datasets(fever_dir, pubhealth_dir, climate_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6f0422-4074-4cbb-bd9e-f012c3d36cea",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "750c1fca-d910-4dfd-b825-b5d5c1b0afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT\n",
    "model_checkpoint = \"../models/BERT_FEVER/checkpoint-4546\"\n",
    "# model_checkpoint = \"../models/BERT_PUBHEALTH/checkpoint-262\"\n",
    "# model_checkpoint = \"../models/BERT_CLIMATE/checkpoint-62\"\n",
    "# model_checkpoint = \"../models/BERT_CLIMATE_V2/best_model\"\n",
    "# model_checkpoint = \"../models/BERT_CLIMATE_V2_best_accuracy/best_model\"\n",
    "# model_checkpoint = \"../models/BERT_CLIMATE_V2_best_loss/best_model\"\n",
    "\n",
    "#RoBERT\n",
    "# model_checkpoint = \"../models/RoBERTa_FEVER/checkpoint-2273\"\n",
    "# model_checkpoint = \"../models/RoBERTa_PUBHEALTH/checkpoint-262\"\n",
    "# model_checkpoint = \"../models/RoBERTa_CLIMATE/checkpoint-93\"\n",
    "\n",
    "\n",
    "#SciBERT\n",
    "# model_checkpoint = \"../models/SciBERT_FEVER/checkpoint-4546\"\n",
    "# model_checkpoint = \"../models/SciBERT_PUBHEALTH/checkpoint-131\"\n",
    "# model_checkpoint = \"../models/SciBERT_CLIMATE/checkpoint-31\"\n",
    "\n",
    "#BioBERT\n",
    "# model_checkpoint = \"../models/BioBERT_FEVER/best_model\"\n",
    "# model_checkpoint = \"../models/BioBERT_PUBHEALTH/best_model\"\n",
    "# model_checkpoint = \"../models/BioBERT_CLIMATE/best_model\"\n",
    "\n",
    "#ALBERT\n",
    "# model_checkpoint = \"../models/ALBERT_FEVER/best_model\"\n",
    "# model_checkpoint = \"../models/ALBERT_PUBHEALTH/best_model\"\n",
    "# model_checkpoint = \"../models/ALBERT_CLIMATE/best_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2a72a4-f7b5-40d8-8818-5b514c52c703",
   "metadata": {},
   "source": [
    "## Run predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b979b0f5-412d-4ba0-8d43-4328dcc7ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def _evaluate(model, ds, device, metric=\"accuracy\"):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model (pytorch model): model to evaluate\n",
    "        ds (torch.DataLoader): dataset to evaluate on loaded into pytorch DataLoader obj\n",
    "        device (torch.device): GPU / CPU\n",
    "        metric (string): evaluation metrics to use. Defaults to accuracy.\n",
    "    \"\"\"\n",
    "    metric = evaluate.load(metric)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    for batch in ds:\n",
    "        batch = {k: v.to(device) for k,v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1)\n",
    "        metric.add_batch(predictions=preds, references=batch[\"labels\"])\n",
    "        predictions = predictions + preds.tolist()\n",
    "        \n",
    "    predictions = np.array(predictions)\n",
    "    metric_val = metric.compute()\n",
    "\n",
    "    return metric_val, predictions\n",
    "\n",
    "def _get_misclassified_samples(ds, predictions):\n",
    "    df = pd.DataFrame(ds)\n",
    "    df['pred'] = predictions\n",
    "    df['misclassified'] = df['label'] != df['pred']\n",
    "    print(df.groupby('label')['misclassified'].value_counts(normalize=True)*100) #misclassified = True\n",
    "    return df\n",
    "\n",
    "def evaluate_model(model_checkpoint, ds_test, metric=\"accuracy\"):\n",
    "    \"\"\"Evaluate accuracy of saved model on test datasets\n",
    "    \n",
    "    Args:\n",
    "        mdoel_checkpoint (string): path to best model,\n",
    "        ds_test (DatasetDict): huggingface dataset for fever_test, pubhealth_test, climate_test,\n",
    "        metric (string): evaluation metrics to use. Defaults to accuracy.\n",
    "    \"\"\"\n",
    "\n",
    "    #===================================================\n",
    "    # Load Model\n",
    "    #===================================================\n",
    "    num_labels = 3 \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_checkpoint, num_labels=num_labels)\n",
    "\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    print(f\"Model loaded into {device}\")\n",
    "    model.to(device)\n",
    "\n",
    "    #===================================================\n",
    "    # Tokenize dataset\n",
    "    #===================================================\n",
    "    print(f\"Tokenizing dataset\")\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "    def preprocess_function(samples):\n",
    "        return tokenizer(samples['claim'], samples['evidence'], \n",
    "                         padding=True,\n",
    "                         truncation='only_second', \n",
    "                         max_length=512)\n",
    "\n",
    "    encoded_ds = ds_test.map(preprocess_function, batched=True)\n",
    "\n",
    "    # format tokens to fit huggingface language model formats\n",
    "    encoded_ds = encoded_ds.remove_columns([\"claim\", \"evidence\"])\n",
    "    encoded_ds = encoded_ds.rename_column(\"label\", \"labels\")\n",
    "    encoded_ds.set_format(\"torch\")\n",
    "\n",
    "    #===================================================\n",
    "    # Evaluate\n",
    "    #===================================================    \n",
    "    error_samples = {}\n",
    "    for ds_name in encoded_ds.keys():\n",
    "        print(f\"Evaluating {ds_name}\")\n",
    "        eval_ds = DataLoader(encoded_ds[ds_name], batch_size=8)\n",
    "        r, predictions = _evaluate(model, eval_ds, device, metric)\n",
    "        print(f\"Overall Accuracy for {ds_name} :: {r}\")\n",
    "\n",
    "        _df = _get_misclassified_samples(ds_test[ds_name], predictions)\n",
    "        error_samples[ds_name] = _df.copy()\n",
    "        \n",
    "    return error_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9abb0d63-1652-4d1d-83ca-f020e0c4ca0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded into cuda\n",
      "Tokenizing dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fever\n",
      "Overall Accuracy for fever :: {'accuracy': 0.6144614461446145}\n",
      "label  misclassified\n",
      "0      False             84.398440\n",
      "       True              15.601560\n",
      "1      True             100.000000\n",
      "2      False             99.939994\n",
      "       True               0.060006\n",
      "Name: misclassified, dtype: float64\n",
      "Evaluating pubhealth\n",
      "Overall Accuracy for pubhealth :: {'accuracy': 0.3556201550387597}\n",
      "label  misclassified\n",
      "0      False             58.263773\n",
      "       True              41.736227\n",
      "1      True             100.000000\n",
      "2      True              60.000000\n",
      "       False             40.000000\n",
      "Name: misclassified, dtype: float64\n",
      "Evaluating climate\n",
      "Overall Accuracy for climate :: {'accuracy': 0.57}\n",
      "label  misclassified\n",
      "0      False             91.578947\n",
      "       True               8.421053\n",
      "1      True             100.000000\n",
      "2      True              60.869565\n",
      "       False             39.130435\n",
      "Name: misclassified, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "error_samples = evaluate_model(model_checkpoint, ds_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaeba1d-b177-48b5-87c8-6816dea43aeb",
   "metadata": {},
   "source": [
    "### get statistics of data distribution by labels for each dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d942b11-489f-4313-8ff4-bbe9f66fd483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds_fever, ds_pubhealth, ds_climate, ds_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "576b1ced-dea5-47d1-8fe4-d1ac481c414c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    33.333333\n",
      "0    33.333333\n",
      "1    33.333333\n",
      "Name: label, dtype: float64\n",
      "2    3333\n",
      "0    3333\n",
      "1    3333\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds_fever['fever_test'])\n",
    "print(df['label'].value_counts(normalize=True)*100)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "89356cc0-266f-4034-a947-f8ec46a52c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    59.904762\n",
      "1    36.190476\n",
      "2     3.904762\n",
      "Name: label, dtype: float64\n",
      "0    629\n",
      "1    380\n",
      "2     41\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds_pubhealth['validation'])\n",
    "print(df['label'].value_counts(normalize=True)*100)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "4d97d56a-39f7-43f8-ba4e-f320ae1979a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    47.298675\n",
      "2    34.352701\n",
      "1    18.348624\n",
      "Name: label, dtype: float64\n",
      "0    464\n",
      "2    337\n",
      "1    180\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds_climate['train'])\n",
    "print(df['label'].value_counts(normalize=True)*100)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "02c69fad-826e-46d8-ac23-1cc717802889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    47.5\n",
      "2    34.0\n",
      "1    18.5\n",
      "Name: label, dtype: float64\n",
      "0    95\n",
      "2    68\n",
      "1    37\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds_climate['validation'])\n",
    "print(df['label'].value_counts(normalize=True)*100)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "859a6136-e2ba-45a9-9cf4-f66ded8e2d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    47.647059\n",
      "2    34.117647\n",
      "1    18.235294\n",
      "Name: label, dtype: float64\n",
      "0    81\n",
      "2    58\n",
      "1    31\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(ds_test['climate'])\n",
    "print(df['label'].value_counts(normalize=True)*100)\n",
    "print(df['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3343df44-c473-44eb-aa90-e48b68994084",
   "metadata": {},
   "source": [
    "### Error Analysis on Climate Fever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5931d68-a35c-42d8-b977-5460cbf7f523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fever', 'pubhealth', 'climate'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdb48f36-04d9-426a-8d5b-89aa33165f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_df = error_samples['climate']\n",
    "_df = _df[_df['misclassified'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d514ba69-f0ee-4b85-b4bf-c52218231dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The effects of global warming include its effects on human health. There are, however, some positive possible aspects to climate change as well. This could negatively affect the affordability of food and the subsequent health of the population. Floods have short and long term negative implications to peoples' health and well being. These melting glaciers have many social and ecological consequences that directly or indirectly impact the health and well-being of humans.\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df[_df['label'] == 1].iloc[1]['evidence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e18cda1-d7bf-486b-ae69-ccbf175fd03a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'receding polar ice caps have little if any negative impact on human health and welfare, and likely a positive benefit'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df[_df['label'] == 1].iloc[1]['claim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c149606e-46e8-4b99-9f29-751db69adca6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
